{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2895076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}, id='c7f7d4c2-1a3f-437f-94a4-9de37562667c'), AIMessage(content='Echo: Hi!', additional_kwargs={}, response_metadata={}, id='52d60598-931e-4c7b-96cd-ea2affe2edd0')]}\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "\n",
    "def echo_node(state: State) -> State:\n",
    "    msg = state.messages[-1].content\n",
    "    state.messages.append(AIMessage(content=f\"Echo: {msg}\"))\n",
    "    return state\n",
    "\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(echo_node)\n",
    "workflow.set_entry_point(\"echo_node\")\n",
    "workflow.add_edge(\"echo_node\", END)\n",
    "graph = workflow.compile()\n",
    "\n",
    "# Run with initial state\n",
    "result = graph.invoke(State(messages=[HumanMessage(content=\"Hi!\")]))\n",
    "print(result)  # \"Echo: Hi!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af0eb749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Echo: Hi!\n"
     ]
    }
   ],
   "source": [
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba8ae98",
   "metadata": {},
   "source": [
    "# Set conditional nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfa10ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991ebc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74316390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21905120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4be815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# Step 1: Define your state\n",
    "class GraphState(dict):\n",
    "    pass\n",
    "\n",
    "\n",
    "# Step 2: Define a simple node that sends message to LLM\n",
    "llm = init_chat_model(\"gpt-4.1-mini\")\n",
    "\n",
    "\n",
    "def chat_node(state: GraphState) -> GraphState:\n",
    "    messages = state.get(\"messages\", [])\n",
    "    response = llm.invoke(messages)\n",
    "    messages.append(AIMessage(content=response.content))\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "\n",
    "# Step 3: Define the graph\n",
    "builder = StateGraph(GraphState)\n",
    "builder.add_node(\"chat\", chat_node)\n",
    "\n",
    "builder.set_entry_point(\"chat\")\n",
    "\n",
    "builder.add_edge(\"chat\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# Step 4: Run it\n",
    "initial_state = {\"messages\": [HumanMessage(content=\"What's the capital of France?\")]}\n",
    "\n",
    "final_state = graph.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bff032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec84bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State:\n",
    "    messages: list[BaseMessage]\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "def generate_response(state):\n",
    "    return {\"messages\": llm.invoke(state[\"messages\"])}\n",
    "\n",
    "\n",
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_node(\"generate_response\", generate_response)\n",
    "\n",
    "graph.add_edge(START, \"generate_response\")\n",
    "graph.add_edge(\"generate_response\", END)\n",
    "\n",
    "graph = graph.compile()\n",
    "\n",
    "graph.invoke({\"messages\": [HumanMessage(content=\"What is the capital of France?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f544b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f35a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"messages\": [HumanMessage(content=\"What is the capital of France?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9fa183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
